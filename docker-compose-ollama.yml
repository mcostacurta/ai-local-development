version: '3.8'

services:
  # Ollama - Local LLM Server
  ollama:
    build: 
      context: .
      dockerfile: Dockerfile-ollama
      args:
        - OLLAMA_MODEL=gemma3:1b
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
    tty: true
    networks:
      - ai_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    # Comment the line below if you have NVIDIA GPU
    runtime: runc

  # ChromaDB - Vector Database
  chromadb:
    image: chromadb/chroma
    container_name: chromadb
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - chromadb_data:/app/chroma_data
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - CHROMA_DB_IMPL=duckdb+parquet
      - CHROMA_PERSIST_DIRECTORY=/chroma/chroma
      - ANONYMIZED_TELEMETRY=False
    networks:
      - ai_network

  # Langflow - Visual Flow Builder for LLMs
  langflow:
    image: langflowai/langflow:latest
    container_name: langflow
    restart: unless-stopped
    ports:
      - "7860:7860"
    volumes:
      - langflow_data:/app/langflow
      - ./flows:/app/flows
    environment:
      - LANGFLOW_HOST=0.0.0.0
      - LANGFLOW_PORT=7860
      - LANGFLOW_WORKERS=1
      - LANGFLOW_SUPERUSER=admin
      - LANGFLOW_SUPERUSER_PASSWORD=admin123
      - LANGFLOW_SECRET_KEY=your-secret-key-here
      - LANGFLOW_DATABASE_URL=sqlite:///./langflow.db
      # Comment above line and uncoment bellow to use postgress 
      # - LANGFLOW_DATABASE_URL=postgresql://langflow:langflow123@postgres:5432/langflow
      - LANGFLOW_AUTO_LOGIN=false
      - LANGFLOW_LOG_LEVEL=INFO
      # Configure connections to other services
      - OLLAMA_BASE_URL=http://ollama:11434
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
    networks:
      - ai_network
    depends_on:
      ollama:
        condition: service_healthy
      chromadb:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Optional: PostgreSQL for persistent storage (alternative to SQLite)
  # postgres:
  #   image: postgres:15-alpine
  #   container_name: postgres
  #   restart: unless-stopped
  #   ports:
  #     - "5432:5432"
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #     - ./init-scripts:/docker-entrypoint-initdb.d
  #   environment:
  #     - POSTGRES_DB=langflow
  #     - POSTGRES_USER=langflow
  #     - POSTGRES_PASSWORD=langflow123
  #     - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
  #   networks:
  #     - ai_network
  #   healthcheck:
  #     test: ["CMD-SHELL", "pg_isready -U langflow -d langflow"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3

networks:
  ai_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  ollama_data:
    driver: local
  chromadb_data:
    driver: local
  langflow_data:
    driver: local
  # postgres_data:
  #   driver: local